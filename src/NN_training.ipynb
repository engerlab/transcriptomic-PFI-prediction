{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13331340-7515-4d2f-b1d2-f41f8fc6feea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 1360 from C header, got 1576 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtuples as tt # Some useful functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import KFold\n",
    "from Mink import science_template\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from pycox.models import LogisticHazard, loss, CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from multi_pipe import load_all\n",
    "from util import n_equal_slices, t_test_feature_selection, pearson_feature_selection, TruSight170\n",
    "from clinical_pipe import impute_scale\n",
    "from ray import tune, train\n",
    "\n",
    "pio.templates['science'] = science_template\n",
    "pio.templates.default = 'science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308a9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "aiosignal                 1.3.1\n",
      "altgraph                  0.17\n",
      "anyio                     3.6.1\n",
      "appdirs                   1.4.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "astroid                   2.6.6\n",
      "asttokens                 2.4.1\n",
      "async-generator           1.10\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "Babel                     2.10.3\n",
      "backcall                  0.2.0\n",
      "beautifulsoup4            4.11.1\n",
      "bleach                    3.3.1\n",
      "blinker                   1.7.0\n",
      "Brotli                    1.0.9\n",
      "brotlicffi                1.1.0.0\n",
      "cached-property           1.5.2\n",
      "celluloid                 0.2.0\n",
      "certifi                   2020.12.5\n",
      "cffi                      1.17.1\n",
      "chardet                   4.0.0\n",
      "charset-normalizer        3.3.2\n",
      "chebpy                    0.2\n",
      "click                     7.1.2\n",
      "colorama                  0.4.4\n",
      "comm                      0.2.2\n",
      "comtypes                  1.1.10\n",
      "contourpy                 1.2.1\n",
      "cycler                    0.10.0\n",
      "debugpy                   1.8.1\n",
      "decorator                 5.0.9\n",
      "defusedxml                0.7.1\n",
      "distlib                   0.3.1\n",
      "docutils                  0.17.1\n",
      "ecos                      2.0.14\n",
      "entrypoints               0.3\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.15.3\n",
      "feather-format            0.4.1\n",
      "filelock                  3.0.12\n",
      "flake8                    4.0.1\n",
      "Flask                     2.0.3\n",
      "fonttools                 4.54.1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2024.6.1\n",
      "future                    0.18.2\n",
      "grpcio                    1.65.4\n",
      "h11                       0.14.0\n",
      "h5py                      3.12.1\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "idna                      2.10\n",
      "importlib-metadata        4.11.4\n",
      "inflate64                 1.0.0\n",
      "ipykernel                 6.29.4\n",
      "ipython                   7.25.0\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "isort                     5.9.3\n",
      "itsdangerous              2.1.2\n",
      "jedi                      0.18.0\n",
      "Jinja2                    3.1.2\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.8\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.22.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.2\n",
      "jupyter-console           6.4.2\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.4\n",
      "jupyterlab-pygments       0.1.2\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "kaleido                   0.2.1\n",
      "Kivy-Garden               0.1.4\n",
      "kiwisolver                1.4.5\n",
      "lazy-object-proxy         1.6.0\n",
      "llvmlite                  0.43.0\n",
      "lxml                      5.2.2\n",
      "Markdown                  3.6\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib                3.9.0\n",
      "matplotlib-inline         0.1.2\n",
      "mccabe                    0.6.1\n",
      "Mink                      0.3.10\n",
      "mistune                   0.8.4\n",
      "mkl-fft                   1.3.8\n",
      "mkl-random                1.2.4\n",
      "mkl-service               2.4.0\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.0.8\n",
      "multivolumefile           0.2.3\n",
      "munkres                   1.1.4\n",
      "nbclassic                 0.3.7\n",
      "nbclient                  0.5.3\n",
      "nbconvert                 6.5.0\n",
      "nbformat                  5.4.0\n",
      "nest-asyncio              1.5.1\n",
      "networkx                  3.3\n",
      "nidaqmx                   0.5.7\n",
      "notebook                  6.4.5\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.60.0\n",
      "numexpr                   2.10.1\n",
      "numpy                     1.26.4\n",
      "oauthlib                  3.1.1\n",
      "osqp                      0.6.7.post0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.2\n",
      "pefile                    2021.5.24\n",
      "pexpect                   4.9.0\n",
      "pickleshare               0.7.5\n",
      "pillow                    10.4.0\n",
      "pip                       24.0\n",
      "platformdirs              4.2.2\n",
      "plotly                    5.22.0\n",
      "prometheus-client         0.11.0\n",
      "prompt-toolkit            3.0.19\n",
      "protobuf                  5.27.3\n",
      "psutil                    5.9.8\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "py7zr                     0.22.0\n",
      "pyarrow                   17.0.0\n",
      "pybcj                     1.0.2\n",
      "pycodestyle               2.8.0\n",
      "pycox                     0.3.0\n",
      "pycparser                 2.22\n",
      "pycryptodomex             3.21.0\n",
      "pydocstyle                6.1.1\n",
      "pyflakes                  2.4.0\n",
      "Pygments                  2.8.1\n",
      "pyinstaller               4.3\n",
      "pyinstaller-hooks-contrib 2021.2\n",
      "pylint                    2.9.6\n",
      "pynder                    0.0.13\n",
      "pyparsing                 3.2.0\n",
      "pyppmd                    1.1.0\n",
      "PyQt5                     5.15.4\n",
      "PyQt5-Qt5                 5.15.2\n",
      "PyQt5-sip                 12.13.0\n",
      "pyrsistent                0.18.0\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0\n",
      "python-dotenv             0.17.1\n",
      "python-json-logger        2.0.7\n",
      "pyttsx3                   2.90\n",
      "pytz                      2024.1\n",
      "pywin32-ctypes            0.2.0\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     26.0.3\n",
      "pyzstd                    0.15.10\n",
      "qdldl                     0.1.7.post4\n",
      "qt5-applications          5.15.2.2.1\n",
      "qt5-tools                 5.15.2.1.0.1\n",
      "qtconsole                 5.3.1\n",
      "QtPy                      2.1.0\n",
      "ray                       2.34.0\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "requests-oauthlib         1.3.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.18.1\n",
      "scikit-learn              1.5.2\n",
      "scikit-survival           0.22.2\n",
      "scipy                     1.14.0\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.3.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.2.0\n",
      "snowballstemmer           2.1.0\n",
      "soupsieve                 2.3.2.post1\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "tenacity                  7.0.0\n",
      "tensorboard               2.17.1\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorboardX              2.6.2.2\n",
      "terminado                 0.10.1\n",
      "testpath                  0.5.0\n",
      "texttable                 1.7.0\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.1.1\n",
      "tk                        0.1.0\n",
      "toml                      0.10.2\n",
      "torch                     2.4.0\n",
      "torchtuples               0.2.2\n",
      "torchvision               0.19.0\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.62.3\n",
      "traitlets                 5.14.3\n",
      "triton                    3.0.0\n",
      "tweepy                    3.10.0\n",
      "types-python-dateutil     2.9.0.20240316\n",
      "typing_extensions         4.11.0\n",
      "tzdata                    2024.1\n",
      "unicodedata2              15.1.0\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "virtualenv                20.4.4\n",
      "wcwidth                   0.2.5\n",
      "webcolors                 24.6.0\n",
      "webencodings              0.5.1\n",
      "webio-jupyter-extension   0.1.0\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.1\n",
      "wheel                     0.43.0\n",
      "widgetsnbextension        4.0.13\n",
      "wrapt                     1.12.1\n",
      "zipfile-deflate64         0.0.0\n",
      "zipp                      3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca204b0-1e2b-4cf7-b61f-8b02ec9f1002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [00:37, 13.81it/s]\n",
      "523it [00:01, 471.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinical_M not in keys\n",
      "clinical_N not in keys\n",
      "clinical_T not in keys\n"
     ]
    }
   ],
   "source": [
    "res_dict = load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650b5a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Dropout(p=0.2, inplace=False)\n",
      "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_net(in_features, out_features, dims, dropout=0.2, seed=54):\n",
    "    non_zero_dims = []\n",
    "    # zero layers should be dropped\n",
    "    for dim in dims:\n",
    "        if dim != 0:\n",
    "            non_zero_dims.append(dim)\n",
    "\n",
    "    dims = non_zero_dims\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if len(dims) == 0:\n",
    "        raise ValueError('Neural network must have at least two layers')\n",
    "\n",
    "    # connect the in_features to the first dimension in the hidden layers\n",
    "    modules = [torch.nn.Linear(in_features, dims[0]),\n",
    "               torch.nn.ReLU(),\n",
    "               torch.nn.BatchNorm1d(dims[0]),\n",
    "               torch.nn.Dropout(dropout)]\n",
    "    \n",
    "    # connect the hidden layers\n",
    "    for i,dim in enumerate(dims[1:]):\n",
    "\n",
    "        modules.append(torch.nn.Linear(dims[i], dim))\n",
    "        modules.append(torch.nn.ReLU())\n",
    "        modules.append(torch.nn.BatchNorm1d(dim))\n",
    "        modules.append(torch.nn.Dropout(dropout))\n",
    "\n",
    "    # didn't add an activation function here\n",
    "    # connect the final hidden layer to the out_features\n",
    "    \n",
    "\n",
    "    modules = modules + [torch.nn.Linear(dims[-1], out_features)]\n",
    "\n",
    "    net = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    net.apply(init_weights)\n",
    "    return net\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "net = make_net(50, 10, [20])\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2ff358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_index_score(model, data, labels, times):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    X_test = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get the survival predictions for the test set\n",
    "    surv_preds = model.predict_surv_df(X_test)\n",
    "    \n",
    "    # Estimate median survival times for each individual\n",
    "    median_surv_times = surv_preds.apply(lambda col: col[col <= 0.5].index[0] if any(col <= 0.5) else col.index[-1], axis=0)\n",
    "\n",
    "    # Compute C-index using true times, event indicators, and predicted times\n",
    "    c_index = concordance_index_censored(labels.astype(bool), times, -median_surv_times)[0]\n",
    "    return c_index\n",
    "\n",
    "def combine_transform_data(DataFrames, train_bool, ) -> list:\n",
    "    '''Take in all the preprocessed data '''\n",
    "\n",
    "    combined_data = DataFrames[0]\n",
    "\n",
    "    for df in DataFrames[1:]:\n",
    "        combined_data = pd.merge(combined_data, df.drop(['time', 'label'], axis=1), on='case_id', how='left')\n",
    "\n",
    "\n",
    "    data = combined_data.loc[:, ~combined_data.columns.isin(['case_id', 'label', 'time','primary_diagnosis_Squamous cell carcinoma, spindle cell'])].values\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    \n",
    "\n",
    "    labels = np.array(combined_data['label'].values, dtype=int)\n",
    "    times = np.array(combined_data['time'].values, dtype=np.float32)\n",
    "\n",
    "    train_set = data[train_bool]\n",
    "    train_labels = labels[train_bool]\n",
    "    train_times = times[train_bool]\n",
    "    test_set = data[~train_bool]\n",
    "    test_times = times[~train_bool]\n",
    "    test_labels = labels[~train_bool]\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "    return train_set, train_labels, train_times, test_set, test_labels, test_times\n",
    "\n",
    "def cross_validate(train_set, y_train, dropout=0.3, num_nodes=[50,50], batch_norm=True, batch_size=50, epochs=10, optimizer=None):\n",
    "    in_features = train_set.shape[1]\n",
    "    out_features = 1\n",
    "\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_set)):\n",
    "        # print(f\"Fold {fold + 1}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        callbacks = [tt.cb.EarlyStopping(patience=5)]\n",
    "        # Define the model and move to GPU\n",
    "        net = make_net(in_features, out_features, num_nodes, dropout=dropout)\n",
    "        \n",
    "        model = CoxPH(net, optimizer)\n",
    "    \n",
    "\n",
    "        # Move data to GPU\n",
    "        X_train, X_val = torch.tensor(train_set[train_idx], dtype=torch.float32).to(device), torch.tensor(train_set[val_idx], dtype=torch.float32).to(device)\n",
    "\n",
    "        # Ensure correct types for durations and events\n",
    "        y_train_durations, y_train_events = y_train  # Unpack y_train into durations and events\n",
    "\n",
    "        # Convert durations to float32 and events to int64\n",
    "        y_train_fold = (\n",
    "            torch.tensor(y_train_durations[train_idx], dtype=torch.float32).to(device),  # Durations as float32\n",
    "            torch.tensor(y_train_events[train_idx], dtype=torch.float32).to(device)       # Events as int64\n",
    "        )\n",
    "\n",
    "        y_val_fold = (\n",
    "            torch.tensor(y_train_durations[val_idx], dtype=torch.float32).to(device),    # Durations as float32\n",
    "            torch.tensor(y_train_events[val_idx], dtype=torch.float32).to(device)         # Events as int64\n",
    "        )\n",
    "\n",
    "        # Training\n",
    "        log = model.fit(X_train, y_train_fold, batch_size, epochs, callbacks, val_data=(X_val, y_val_fold), verbose=False)\n",
    "        \n",
    "        scores.append(model.score_in_batches((X_val, y_val_fold))['loss'])\n",
    "    \n",
    "    mean_score = sum(scores) / len(scores)\n",
    "\n",
    "    return mean_score, model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multi_training(data_dict, seed: int, fusion_type: str, datatypes: list) -> list:\n",
    "    \n",
    "    \n",
    "    miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times = data_dict['mirna']\n",
    "    mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times = data_dict['mrna']\n",
    "    clinical_df = data_dict['clinical']\n",
    "    \n",
    "    rs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(seed)))\n",
    "    random_order = np.arange(0,len(clinical_df))\n",
    "    rs.shuffle(random_order)\n",
    "    slices = n_equal_slices(len(clinical_df), 5)\n",
    "\n",
    "    c_vals = []\n",
    "\n",
    "    for bound in slices:\n",
    "\n",
    "        \n",
    "        test_set = random_order[bound[0]:bound[1]]\n",
    "        \n",
    "\n",
    "        test_bool = np.array([True if i in test_set else False for i in range(len(random_order))], dtype=bool)\n",
    "        train_bool = ~test_bool\n",
    "        \n",
    "\n",
    "\n",
    "        mRNA_df = t_test_feature_selection(train_bool, mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times, 20)\n",
    "        miRNA_df = t_test_feature_selection(train_bool, miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times, 100)\n",
    "        scaled = impute_scale(clinical_df.loc[:, ~clinical_df.columns.isin(['case_id', 'label', 'time'])], train_bool)\n",
    "        \n",
    "        # print(clinical_df[['case_id', 'label', 'time']].values.shape)\n",
    "\n",
    "        labeled = np.concatenate((scaled, clinical_df[['case_id', 'label', 'time']].values), axis=1)\n",
    "        clinical_df = pd.DataFrame(data=labeled, columns=clinical_df.columns)\n",
    "\n",
    "        processed_data = {'mrna': mRNA_df, 'mirna': miRNA_df, 'clinical': clinical_df}\n",
    "\n",
    "        arg = []\n",
    "        for datatype in datatypes:\n",
    "            arg.append(processed_data[datatype])\n",
    "\n",
    "        train_set, train_labels, train_times, test_set, test_labels, test_times = combine_transform_data(arg, train_bool)\n",
    "\n",
    "       \n",
    "        \n",
    "        y_train = (train_times, train_labels)\n",
    "        y_test = (test_times, test_labels)\n",
    "        \n",
    "        optimizer = tt.optim.RMSprop(lr=0.007)\n",
    "        res, model = cross_validate(train_set, y_train,  dropout=0.5, num_nodes=[50,50], batch_size=32, optimizer=optimizer)\n",
    "        # I don't understand this but it has to be done first\n",
    "        _ = model.compute_baseline_hazards()\n",
    "        c = c_index_score(model, test_set, test_labels, test_times)\n",
    "        print(c)\n",
    "        c_vals.append(c)\n",
    "        \n",
    "\n",
    "    return c_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c3b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538961038961039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6089546502690238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5254208754208755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5426425099425541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n",
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5815824765310684\n",
      "0.5595123102249122 +/- 0.06928786379262097\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "c_vals = multi_training(res_dict, 42, 'early', ['clinical'])\n",
    "print(f\"{np.mean(c_vals)} +/- {2*np.std(c_vals, ddof=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a165daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(train_set, y_train, test_set, y_test, optimal_dict):\n",
    "    X_train= torch.tensor(train_set, dtype=torch.float32)\n",
    "    # Ensure correct types for durations and events\n",
    "    y_train_durations, y_train_events = y_train  # Unpack y_train into durations and events\n",
    "\n",
    "    # Convert durations to float32 and events to int64\n",
    "    y_train_fold = (\n",
    "        torch.tensor(y_train_durations, dtype=torch.float32),  \n",
    "        torch.tensor(y_train_events, dtype=torch.float32)      \n",
    "    )\n",
    "\n",
    "    callbacks = [tt.cb.EarlyStopping(patience=5, dataset='train')]\n",
    "\n",
    "    optimizer = tt.optim.RMSprop(lr=optimal_dict[\"lr\"], momentum=optimal_dict[\"momentum\"])\n",
    "    # print(X_train)\n",
    "    net = make_net(X_train.shape[1], 1, [int(optimal_dict['dim1']), int(optimal_dict['dim2'])], dropout=optimal_dict['dropout'])\n",
    "\n",
    "    model = CoxPH(net, optimizer)\n",
    "    \n",
    "    log = model.fit(X_train, y_train_fold, int(optimal_dict['batch']), 100, callbacks, verbose=False)\n",
    "\n",
    "    risk = model.predict(test_set).squeeze()\n",
    "\n",
    "    return concordance_index_censored(y_test[1]==1, y_test[0], risk)\n",
    "\n",
    "\n",
    "def outer_validation(data_dict, seed: int, fusion_type: str, datatypes: list) -> list:\n",
    "    \n",
    "    def train_omics(config):\n",
    "\n",
    "        if config['optimizer'] == 0:\n",
    "            optimizer = tt.optim.AdamW(lr=config[\"lr\"], betas=(config[\"B1\"], config[\"B2\"]))\n",
    "        elif config['optimizer'] == 1:\n",
    "            optimizer = tt.optim.RMSprop(lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "            \n",
    "        train_set = torch.load(\"/home/elliotw/Elliot_NN_optimizing/data_tmp/train.pt\")\n",
    "        y_train = torch.load(\"/home/elliotw/Elliot_NN_optimizing/data_tmp/val.pt\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        dims = [config['dim1'], config['dim2']]\n",
    "        \n",
    "\n",
    "        res, _ = cross_validate(train_set, y_train, \n",
    "                            dropout=config['dropout'], \n",
    "                            num_nodes=dims, \n",
    "                            batch_size=config['batch'], \n",
    "                            optimizer=optimizer, \n",
    "                            )\n",
    "\n",
    "        train.report({\"score\": res})\n",
    "    \n",
    "    miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times = data_dict['mirna']\n",
    "    mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times = data_dict['mrna']\n",
    "    clinical_df = data_dict['clinical']\n",
    "    \n",
    "    rs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(seed)))\n",
    "    random_order = np.arange(0,len(clinical_df))\n",
    "    rs.shuffle(random_order)\n",
    "    slices = n_equal_slices(len(clinical_df), 5)\n",
    "\n",
    "    c_vals = []\n",
    "\n",
    "    for bound in slices:\n",
    "\n",
    "        # this is inside the for loop because it is overwritten at the end to avoid missing arguments not tuned in raytuner\n",
    "        grid_space = {\n",
    "            \"lr\": tune.grid_search([0.001, 0.005, 0.0075, 0.01, 0.03, 0.05]),\n",
    "            \"B1\": 0.9,\n",
    "            \"B2\": 0.99,\n",
    "            \"dim1\": tune.grid_search([50,100]),\n",
    "            \"dim2\": tune.grid_search([50,100]),\n",
    "            \"dropout\": tune.grid_search([0.2, 0.5]),\n",
    "            \"batch\": 32,\n",
    "            \"momentum\": 0,\n",
    "            \"optimizer\": 1\n",
    "        }\n",
    "\n",
    "        \n",
    "        test_set = random_order[bound[0]:bound[1]]\n",
    "        test_bool = np.array([True if i in test_set else False for i in range(len(random_order))], dtype=bool)\n",
    "        train_bool = ~test_bool\n",
    "        \n",
    "        mRNA_df = TruSight170(train_bool, mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times)\n",
    "        miRNA_df = pearson_feature_selection(train_bool, miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times, 100)\n",
    "        scaled = impute_scale(clinical_df.loc[:, ~clinical_df.columns.isin(['case_id', 'label', 'time'])], train_bool)\n",
    "\n",
    "        labeled = np.concatenate((scaled, clinical_df[['case_id', 'label', 'time']].values), axis=1)\n",
    "        clinical_df = pd.DataFrame(data=labeled, columns=clinical_df.columns)\n",
    "        processed_data = {'mrna': mRNA_df, 'mirna': miRNA_df, 'clinical': clinical_df}\n",
    "\n",
    "        arg = []\n",
    "        for datatype in datatypes:\n",
    "            arg.append(processed_data[datatype])\n",
    "\n",
    "        train_set, train_labels, train_times, test_set, test_labels, test_times = combine_transform_data(arg, train_bool)\n",
    "        y_train = (train_times, train_labels)\n",
    "        y_test = (test_times, test_labels)\n",
    "\n",
    "        torch.save(train_set, \"./data_tmp/train.pt\")\n",
    "        torch.save(y_train,\"./data_tmp/val.pt\")\n",
    "        train_omics = tune.with_resources(train_omics, {\"gpu\": 0.25})\n",
    "\n",
    "        tuner = tune.Tuner(\n",
    "            train_omics,\n",
    "            param_space=grid_space,\n",
    "            tune_config=tune.TuneConfig(\n",
    "                # num_samples=100,\n",
    "                metric=\"score\",\n",
    "                mode=\"min\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        results = tuner.fit()\n",
    "        best_result = min(results, key= lambda x: x.metrics['score'])\n",
    "        print(best_result)\n",
    "        parameters = best_result.path.split('_')[-3].split(',')\n",
    "\n",
    "        for param in parameters:\n",
    "            key, value = param.split('=')\n",
    "            value = float(value)\n",
    "            grid_space[key] = value\n",
    "\n",
    "        c = retrain(train_set, y_train, test_set, y_test, grid_space)[0]\n",
    "        \n",
    "        c_vals.append(c)\n",
    "\n",
    "    return c_vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b229d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/Elliot_NN_optimizing/util.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = ((controls_feature_mean - cases_feature_mean) - mudiff)/pooledSE\n"
     ]
    }
   ],
   "source": [
    "miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times = res_dict['mirna']\n",
    "mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times = res_dict['mrna']\n",
    "clinical_df = res_dict['clinical']\n",
    "\n",
    "rs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(4)))\n",
    "random_order = np.arange(0,len(clinical_df))\n",
    "rs.shuffle(random_order)\n",
    "slices = n_equal_slices(len(clinical_df), 5)\n",
    "\n",
    "test_set = random_order[slices[0][0]:slices[0][1]]\n",
    "test_bool = np.array([True if i in test_set else False for i in range(len(random_order))], dtype=bool)\n",
    "train_bool = ~test_bool\n",
    "\n",
    "mRNA_df = t_test_feature_selection(train_bool, mRNA_id, mRNA_data, mRNA_gene_names, mRNA_matched_labels, mRNA_matched_times, 20)\n",
    "miRNA_df = t_test_feature_selection(train_bool, miRNA_id, miRNA_data, miRNA_gene_names, miRNA_matched_labels, miRNA_matched_times, 100)\n",
    "scaled = impute_scale(clinical_df.loc[:, ~clinical_df.columns.isin(['case_id', 'label', 'time'])], train_bool)\n",
    "\n",
    "labeled = np.concatenate((scaled, clinical_df[['case_id', 'label', 'time']].values), axis=1)\n",
    "clinical_df = pd.DataFrame(data=labeled, columns=clinical_df.columns)\n",
    "\n",
    "processed_data = {'mrna': mRNA_df, 'mirna': miRNA_df, 'clinical': clinical_df}\n",
    "\n",
    "arg = []\n",
    "for datatype in ['mrna']:\n",
    "    arg.append(processed_data[datatype])\n",
    "\n",
    "\n",
    "train_set, train_labels, train_times, test_set, test_labels, test_times = combine_transform_data(arg, train_bool)\n",
    "print(train_set.shape)\n",
    "num_durations = 100\n",
    "\n",
    "y_train = (train_times, train_labels)\n",
    "y_test = (test_times, test_labels)\n",
    "    \n",
    "torch.save(train_set, \"./data_tmp/train.pt\")\n",
    "torch.save(y_train,\"./data_tmp/val.pt\")\n",
    "\n",
    "\n",
    "def train_omics(config):\n",
    "\n",
    "    if config['optimizer'] == 0:\n",
    "        optimizer = tt.optim.AdamW(lr=config[\"lr\"], betas=(config[\"B1\"], config[\"B2\"]))\n",
    "    elif config['optimizer'] == 1:\n",
    "        optimizer = tt.optim.RMSprop(lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "        \n",
    "    train_set = torch.load(\"/home/elliotw/Elliot_NN_optimizing/data_tmp/train.pt\")\n",
    "    y_train = torch.load(\"/home/elliotw/Elliot_NN_optimizing/data_tmp/val.pt\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    dims = [config['dim1'], config['dim2']]\n",
    "    \n",
    "\n",
    "    res, _ = cross_validate(train_set, y_train, \n",
    "                        dropout=config['dropout'], \n",
    "                        num_nodes=dims, \n",
    "                        batch_size=config['batch'], \n",
    "                        optimizer=optimizer, \n",
    "                        )\n",
    "\n",
    "    train.report({\"score\": res})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5438e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-16 10:13:42</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:47.41        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.4/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/32 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  dim1</th><th style=\"text-align: right;\">  dim2</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_omics_3a124_00000</td><td>TERMINATED</td><td>172.21.21.61:3389074</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.55427</td><td style=\"text-align: right;\">3.93063</td></tr>\n",
       "<tr><td>train_omics_3a124_00001</td><td>TERMINATED</td><td>172.21.21.61:3389075</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.49816</td><td style=\"text-align: right;\">4.06255</td></tr>\n",
       "<tr><td>train_omics_3a124_00002</td><td>TERMINATED</td><td>172.21.21.61:3389076</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.49251</td><td style=\"text-align: right;\">3.98954</td></tr>\n",
       "<tr><td>train_omics_3a124_00003</td><td>TERMINATED</td><td>172.21.21.61:3389077</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.52986</td><td style=\"text-align: right;\">3.98892</td></tr>\n",
       "<tr><td>train_omics_3a124_00004</td><td>TERMINATED</td><td>172.21.21.61:3389378</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.54301</td><td style=\"text-align: right;\">3.77677</td></tr>\n",
       "<tr><td>train_omics_3a124_00005</td><td>TERMINATED</td><td>172.21.21.61:3389379</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.60378</td><td style=\"text-align: right;\">3.96691</td></tr>\n",
       "<tr><td>train_omics_3a124_00006</td><td>TERMINATED</td><td>172.21.21.61:3389380</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.51834</td><td style=\"text-align: right;\">3.93053</td></tr>\n",
       "<tr><td>train_omics_3a124_00007</td><td>TERMINATED</td><td>172.21.21.61:3389381</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.52216</td><td style=\"text-align: right;\">3.87021</td></tr>\n",
       "<tr><td>train_omics_3a124_00008</td><td>TERMINATED</td><td>172.21.21.61:3389678</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.5631 </td><td style=\"text-align: right;\">3.9148 </td></tr>\n",
       "<tr><td>train_omics_3a124_00009</td><td>TERMINATED</td><td>172.21.21.61:3389679</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.58349</td><td style=\"text-align: right;\">3.94003</td></tr>\n",
       "<tr><td>train_omics_3a124_00010</td><td>TERMINATED</td><td>172.21.21.61:3389680</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.53951</td><td style=\"text-align: right;\">3.91973</td></tr>\n",
       "<tr><td>train_omics_3a124_00011</td><td>TERMINATED</td><td>172.21.21.61:3389681</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.59484</td><td style=\"text-align: right;\">3.99953</td></tr>\n",
       "<tr><td>train_omics_3a124_00012</td><td>TERMINATED</td><td>172.21.21.61:3389980</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.70919</td><td style=\"text-align: right;\">3.80401</td></tr>\n",
       "<tr><td>train_omics_3a124_00013</td><td>TERMINATED</td><td>172.21.21.61:3389981</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.65199</td><td style=\"text-align: right;\">3.8964 </td></tr>\n",
       "<tr><td>train_omics_3a124_00014</td><td>TERMINATED</td><td>172.21.21.61:3389982</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.60698</td><td style=\"text-align: right;\">3.82022</td></tr>\n",
       "<tr><td>train_omics_3a124_00015</td><td>TERMINATED</td><td>172.21.21.61:3389983</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.73726</td><td style=\"text-align: right;\">3.7936 </td></tr>\n",
       "<tr><td>train_omics_3a124_00016</td><td>TERMINATED</td><td>172.21.21.61:3390281</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.63018</td><td style=\"text-align: right;\">3.94496</td></tr>\n",
       "<tr><td>train_omics_3a124_00017</td><td>TERMINATED</td><td>172.21.21.61:3390282</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.60618</td><td style=\"text-align: right;\">3.97515</td></tr>\n",
       "<tr><td>train_omics_3a124_00018</td><td>TERMINATED</td><td>172.21.21.61:3390283</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.62952</td><td style=\"text-align: right;\">3.99278</td></tr>\n",
       "<tr><td>train_omics_3a124_00019</td><td>TERMINATED</td><td>172.21.21.61:3390284</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.59929</td><td style=\"text-align: right;\">4.04785</td></tr>\n",
       "<tr><td>train_omics_3a124_00020</td><td>TERMINATED</td><td>172.21.21.61:3390581</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.8353 </td><td style=\"text-align: right;\">3.8141 </td></tr>\n",
       "<tr><td>train_omics_3a124_00021</td><td>TERMINATED</td><td>172.21.21.61:3390582</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.69343</td><td style=\"text-align: right;\">3.80208</td></tr>\n",
       "<tr><td>train_omics_3a124_00022</td><td>TERMINATED</td><td>172.21.21.61:3390583</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.78817</td><td style=\"text-align: right;\">3.80524</td></tr>\n",
       "<tr><td>train_omics_3a124_00023</td><td>TERMINATED</td><td>172.21.21.61:3390584</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.0075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.87238</td><td style=\"text-align: right;\">3.86632</td></tr>\n",
       "<tr><td>train_omics_3a124_00024</td><td>TERMINATED</td><td>172.21.21.61:3390884</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.6208 </td><td style=\"text-align: right;\">3.92816</td></tr>\n",
       "<tr><td>train_omics_3a124_00025</td><td>TERMINATED</td><td>172.21.21.61:3390885</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.57466</td><td style=\"text-align: right;\">3.97684</td></tr>\n",
       "<tr><td>train_omics_3a124_00026</td><td>TERMINATED</td><td>172.21.21.61:3390886</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.61786</td><td style=\"text-align: right;\">3.98534</td></tr>\n",
       "<tr><td>train_omics_3a124_00027</td><td>TERMINATED</td><td>172.21.21.61:3390887</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.72407</td><td style=\"text-align: right;\">3.96475</td></tr>\n",
       "<tr><td>train_omics_3a124_00028</td><td>TERMINATED</td><td>172.21.21.61:3391188</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.75806</td><td style=\"text-align: right;\">3.7851 </td></tr>\n",
       "<tr><td>train_omics_3a124_00029</td><td>TERMINATED</td><td>172.21.21.61:3391189</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.60924</td><td style=\"text-align: right;\">3.84693</td></tr>\n",
       "<tr><td>train_omics_3a124_00030</td><td>TERMINATED</td><td>172.21.21.61:3391190</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.74334</td><td style=\"text-align: right;\">3.86305</td></tr>\n",
       "<tr><td>train_omics_3a124_00031</td><td>TERMINATED</td><td>172.21.21.61:3391191</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.7649 </td><td style=\"text-align: right;\">3.80995</td></tr>\n",
       "<tr><td>train_omics_3a124_00032</td><td>TERMINATED</td><td>172.21.21.61:3391490</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.69463</td><td style=\"text-align: right;\">3.88373</td></tr>\n",
       "<tr><td>train_omics_3a124_00033</td><td>TERMINATED</td><td>172.21.21.61:3391491</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.67206</td><td style=\"text-align: right;\">3.92886</td></tr>\n",
       "<tr><td>train_omics_3a124_00034</td><td>TERMINATED</td><td>172.21.21.61:3391492</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.7322 </td><td style=\"text-align: right;\">3.98582</td></tr>\n",
       "<tr><td>train_omics_3a124_00035</td><td>TERMINATED</td><td>172.21.21.61:3391493</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.79647</td><td style=\"text-align: right;\">3.94401</td></tr>\n",
       "<tr><td>train_omics_3a124_00036</td><td>TERMINATED</td><td>172.21.21.61:3391791</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.77032</td><td style=\"text-align: right;\">3.79972</td></tr>\n",
       "<tr><td>train_omics_3a124_00037</td><td>TERMINATED</td><td>172.21.21.61:3391792</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.67153</td><td style=\"text-align: right;\">3.87254</td></tr>\n",
       "<tr><td>train_omics_3a124_00038</td><td>TERMINATED</td><td>172.21.21.61:3391793</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.77254</td><td style=\"text-align: right;\">3.84621</td></tr>\n",
       "<tr><td>train_omics_3a124_00039</td><td>TERMINATED</td><td>172.21.21.61:3391794</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.03  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.82977</td><td style=\"text-align: right;\">3.817  </td></tr>\n",
       "<tr><td>train_omics_3a124_00040</td><td>TERMINATED</td><td>172.21.21.61:3392091</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.80906</td><td style=\"text-align: right;\">3.82702</td></tr>\n",
       "<tr><td>train_omics_3a124_00041</td><td>TERMINATED</td><td>172.21.21.61:3392092</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.72834</td><td style=\"text-align: right;\">3.85208</td></tr>\n",
       "<tr><td>train_omics_3a124_00042</td><td>TERMINATED</td><td>172.21.21.61:3392093</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.79784</td><td style=\"text-align: right;\">3.86128</td></tr>\n",
       "<tr><td>train_omics_3a124_00043</td><td>TERMINATED</td><td>172.21.21.61:3392094</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.86657</td><td style=\"text-align: right;\">3.95151</td></tr>\n",
       "<tr><td>train_omics_3a124_00044</td><td>TERMINATED</td><td>172.21.21.61:3392393</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.83217</td><td style=\"text-align: right;\">3.78854</td></tr>\n",
       "<tr><td>train_omics_3a124_00045</td><td>TERMINATED</td><td>172.21.21.61:3392394</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.68294</td><td style=\"text-align: right;\">3.8655 </td></tr>\n",
       "<tr><td>train_omics_3a124_00046</td><td>TERMINATED</td><td>172.21.21.61:3392395</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.8042 </td><td style=\"text-align: right;\">3.83308</td></tr>\n",
       "<tr><td>train_omics_3a124_00047</td><td>TERMINATED</td><td>172.21.21.61:3392396</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.86824</td><td style=\"text-align: right;\">3.75341</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 10:13:42,831\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/elliotw/ray_results/train_omics_2024-12-16_10-12-55' in 0.0059s.\n",
      "2024-12-16 10:13:42,835\tINFO tune.py:1041 -- Total run time: 47.42 seconds (47.41 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'score': 3.75340576171875},\n",
      "  path='/home/elliotw/ray_results/train_omics_2024-12-16_10-12-55/train_omics_3a124_00047_47_dim1=100,dim2=100,dropout=0.5000,lr=0.0500_2024-12-16_10-12-55',\n",
      "  filesystem='local',\n",
      "  checkpoint=None\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "res = outer_validation(res_dict, 6, '', ['mirna','mrna','clinical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f31326ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5988601490574309, 0.5208845208845209, 0.536328125, 0.6875525651808242, 0.659264399722415]\n",
      "0.6005779519690382 +/- 0.058638849325227095\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "\n",
    "print(f\"{np.mean(res)} +/- {2*np.std(res)/np.sqrt(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73e7cc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-18 12:57:57</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:48.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.4/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/32 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  dim1</th><th style=\"text-align: right;\">  dim2</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_omics_87f7a_00000</td><td>TERMINATED</td><td>172.21.21.61:2162159</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.14727</td><td style=\"text-align: right;\">3.75474</td></tr>\n",
       "<tr><td>train_omics_87f7a_00001</td><td>TERMINATED</td><td>172.21.21.61:2162160</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05859</td><td style=\"text-align: right;\">3.82707</td></tr>\n",
       "<tr><td>train_omics_87f7a_00002</td><td>TERMINATED</td><td>172.21.21.61:2162161</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.14967</td><td style=\"text-align: right;\">3.77997</td></tr>\n",
       "<tr><td>train_omics_87f7a_00003</td><td>TERMINATED</td><td>172.21.21.61:2162162</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.10195</td><td style=\"text-align: right;\">3.77514</td></tr>\n",
       "<tr><td>train_omics_87f7a_00004</td><td>TERMINATED</td><td>172.21.21.61:2162460</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.06738</td><td style=\"text-align: right;\">3.81092</td></tr>\n",
       "<tr><td>train_omics_87f7a_00005</td><td>TERMINATED</td><td>172.21.21.61:2162461</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.03584</td><td style=\"text-align: right;\">3.84528</td></tr>\n",
       "<tr><td>train_omics_87f7a_00006</td><td>TERMINATED</td><td>172.21.21.61:2162462</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.16596</td><td style=\"text-align: right;\">3.76416</td></tr>\n",
       "<tr><td>train_omics_87f7a_00007</td><td>TERMINATED</td><td>172.21.21.61:2162463</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.11425</td><td style=\"text-align: right;\">3.7805 </td></tr>\n",
       "<tr><td>train_omics_87f7a_00008</td><td>TERMINATED</td><td>172.21.21.61:2162760</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.12594</td><td style=\"text-align: right;\">3.71318</td></tr>\n",
       "<tr><td>train_omics_87f7a_00009</td><td>TERMINATED</td><td>172.21.21.61:2162761</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05461</td><td style=\"text-align: right;\">3.84049</td></tr>\n",
       "<tr><td>train_omics_87f7a_00010</td><td>TERMINATED</td><td>172.21.21.61:2162762</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.12275</td><td style=\"text-align: right;\">3.75362</td></tr>\n",
       "<tr><td>train_omics_87f7a_00011</td><td>TERMINATED</td><td>172.21.21.61:2162763</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.17337</td><td style=\"text-align: right;\">3.80278</td></tr>\n",
       "<tr><td>train_omics_87f7a_00012</td><td>TERMINATED</td><td>172.21.21.61:2163060</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.12583</td><td style=\"text-align: right;\">3.74385</td></tr>\n",
       "<tr><td>train_omics_87f7a_00013</td><td>TERMINATED</td><td>172.21.21.61:2163061</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.16833</td><td style=\"text-align: right;\">3.81396</td></tr>\n",
       "<tr><td>train_omics_87f7a_00014</td><td>TERMINATED</td><td>172.21.21.61:2163062</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.19189</td><td style=\"text-align: right;\">3.75761</td></tr>\n",
       "<tr><td>train_omics_87f7a_00015</td><td>TERMINATED</td><td>172.21.21.61:2163063</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.15637</td><td style=\"text-align: right;\">3.7837 </td></tr>\n",
       "<tr><td>train_omics_87f7a_00016</td><td>TERMINATED</td><td>172.21.21.61:2163361</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05602</td><td style=\"text-align: right;\">3.76952</td></tr>\n",
       "<tr><td>train_omics_87f7a_00017</td><td>TERMINATED</td><td>172.21.21.61:2163362</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.02068</td><td style=\"text-align: right;\">3.83694</td></tr>\n",
       "<tr><td>train_omics_87f7a_00018</td><td>TERMINATED</td><td>172.21.21.61:2163363</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.15658</td><td style=\"text-align: right;\">3.88583</td></tr>\n",
       "<tr><td>train_omics_87f7a_00019</td><td>TERMINATED</td><td>172.21.21.61:2163364</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.10726</td><td style=\"text-align: right;\">3.83575</td></tr>\n",
       "<tr><td>train_omics_87f7a_00020</td><td>TERMINATED</td><td>172.21.21.61:2163661</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.18294</td><td style=\"text-align: right;\">3.73367</td></tr>\n",
       "<tr><td>train_omics_87f7a_00021</td><td>TERMINATED</td><td>172.21.21.61:2163662</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.14246</td><td style=\"text-align: right;\">3.82235</td></tr>\n",
       "<tr><td>train_omics_87f7a_00022</td><td>TERMINATED</td><td>172.21.21.61:2163663</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.18674</td><td style=\"text-align: right;\">3.83343</td></tr>\n",
       "<tr><td>train_omics_87f7a_00023</td><td>TERMINATED</td><td>172.21.21.61:2163664</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.23102</td><td style=\"text-align: right;\">3.79742</td></tr>\n",
       "<tr><td>train_omics_87f7a_00024</td><td>TERMINATED</td><td>172.21.21.61:2163961</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.25436</td><td style=\"text-align: right;\">3.86593</td></tr>\n",
       "<tr><td>train_omics_87f7a_00025</td><td>TERMINATED</td><td>172.21.21.61:2163962</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.21973</td><td style=\"text-align: right;\">3.91225</td></tr>\n",
       "<tr><td>train_omics_87f7a_00026</td><td>TERMINATED</td><td>172.21.21.61:2163963</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.31148</td><td style=\"text-align: right;\">3.85506</td></tr>\n",
       "<tr><td>train_omics_87f7a_00027</td><td>TERMINATED</td><td>172.21.21.61:2163964</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.34532</td><td style=\"text-align: right;\">4.04626</td></tr>\n",
       "<tr><td>train_omics_87f7a_00028</td><td>TERMINATED</td><td>172.21.21.61:2164262</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.27605</td><td style=\"text-align: right;\">3.8172 </td></tr>\n",
       "<tr><td>train_omics_87f7a_00029</td><td>TERMINATED</td><td>172.21.21.61:2164263</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.169  </td><td style=\"text-align: right;\">3.84833</td></tr>\n",
       "<tr><td>train_omics_87f7a_00030</td><td>TERMINATED</td><td>172.21.21.61:2164264</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.35436</td><td style=\"text-align: right;\">3.90564</td></tr>\n",
       "<tr><td>train_omics_87f7a_00031</td><td>TERMINATED</td><td>172.21.21.61:2164265</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.34914</td><td style=\"text-align: right;\">3.85013</td></tr>\n",
       "<tr><td>train_omics_87f7a_00032</td><td>TERMINATED</td><td>172.21.21.61:2164562</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.08625</td><td style=\"text-align: right;\">3.74723</td></tr>\n",
       "<tr><td>train_omics_87f7a_00033</td><td>TERMINATED</td><td>172.21.21.61:2164563</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.01348</td><td style=\"text-align: right;\">3.81865</td></tr>\n",
       "<tr><td>train_omics_87f7a_00034</td><td>TERMINATED</td><td>172.21.21.61:2164564</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.15788</td><td style=\"text-align: right;\">3.76302</td></tr>\n",
       "<tr><td>train_omics_87f7a_00035</td><td>TERMINATED</td><td>172.21.21.61:2164565</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05253</td><td style=\"text-align: right;\">3.77423</td></tr>\n",
       "<tr><td>train_omics_87f7a_00036</td><td>TERMINATED</td><td>172.21.21.61:2164862</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.17155</td><td style=\"text-align: right;\">3.79243</td></tr>\n",
       "<tr><td>train_omics_87f7a_00037</td><td>TERMINATED</td><td>172.21.21.61:2164863</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.14067</td><td style=\"text-align: right;\">3.83636</td></tr>\n",
       "<tr><td>train_omics_87f7a_00038</td><td>TERMINATED</td><td>172.21.21.61:2164864</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.20606</td><td style=\"text-align: right;\">3.79239</td></tr>\n",
       "<tr><td>train_omics_87f7a_00039</td><td>TERMINATED</td><td>172.21.21.61:2164865</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.20623</td><td style=\"text-align: right;\">3.765  </td></tr>\n",
       "<tr><td>train_omics_87f7a_00040</td><td>TERMINATED</td><td>172.21.21.61:2165163</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.15439</td><td style=\"text-align: right;\">3.72669</td></tr>\n",
       "<tr><td>train_omics_87f7a_00041</td><td>TERMINATED</td><td>172.21.21.61:2165164</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05854</td><td style=\"text-align: right;\">3.81881</td></tr>\n",
       "<tr><td>train_omics_87f7a_00042</td><td>TERMINATED</td><td>172.21.21.61:2165165</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.14322</td><td style=\"text-align: right;\">3.81332</td></tr>\n",
       "<tr><td>train_omics_87f7a_00043</td><td>TERMINATED</td><td>172.21.21.61:2165166</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1373 </td><td style=\"text-align: right;\">3.81315</td></tr>\n",
       "<tr><td>train_omics_87f7a_00044</td><td>TERMINATED</td><td>172.21.21.61:2165463</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.19655</td><td style=\"text-align: right;\">3.72813</td></tr>\n",
       "<tr><td>train_omics_87f7a_00045</td><td>TERMINATED</td><td>172.21.21.61:2165464</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05022</td><td style=\"text-align: right;\">3.82846</td></tr>\n",
       "<tr><td>train_omics_87f7a_00046</td><td>TERMINATED</td><td>172.21.21.61:2165465</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.10467</td><td style=\"text-align: right;\">3.83415</td></tr>\n",
       "<tr><td>train_omics_87f7a_00047</td><td>TERMINATED</td><td>172.21.21.61:2165466</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1205 </td><td style=\"text-align: right;\">3.79168</td></tr>\n",
       "<tr><td>train_omics_87f7a_00048</td><td>TERMINATED</td><td>172.21.21.61:2165764</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.13386</td><td style=\"text-align: right;\">3.73667</td></tr>\n",
       "<tr><td>train_omics_87f7a_00049</td><td>TERMINATED</td><td>172.21.21.61:2165765</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.10128</td><td style=\"text-align: right;\">3.86954</td></tr>\n",
       "<tr><td>train_omics_87f7a_00050</td><td>TERMINATED</td><td>172.21.21.61:2165766</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.21451</td><td style=\"text-align: right;\">3.87556</td></tr>\n",
       "<tr><td>train_omics_87f7a_00051</td><td>TERMINATED</td><td>172.21.21.61:2165767</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.18074</td><td style=\"text-align: right;\">3.87869</td></tr>\n",
       "<tr><td>train_omics_87f7a_00052</td><td>TERMINATED</td><td>172.21.21.61:2166064</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.10777</td><td style=\"text-align: right;\">3.75898</td></tr>\n",
       "<tr><td>train_omics_87f7a_00053</td><td>TERMINATED</td><td>172.21.21.61:2166065</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.06331</td><td style=\"text-align: right;\">3.8378 </td></tr>\n",
       "<tr><td>train_omics_87f7a_00054</td><td>TERMINATED</td><td>172.21.21.61:2166066</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.15999</td><td style=\"text-align: right;\">3.78247</td></tr>\n",
       "<tr><td>train_omics_87f7a_00055</td><td>TERMINATED</td><td>172.21.21.61:2166067</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.21482</td><td style=\"text-align: right;\">3.81988</td></tr>\n",
       "<tr><td>train_omics_87f7a_00056</td><td>TERMINATED</td><td>172.21.21.61:2166365</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.2148 </td><td style=\"text-align: right;\">3.79136</td></tr>\n",
       "<tr><td>train_omics_87f7a_00057</td><td>TERMINATED</td><td>172.21.21.61:2166366</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.16847</td><td style=\"text-align: right;\">3.90891</td></tr>\n",
       "<tr><td>train_omics_87f7a_00058</td><td>TERMINATED</td><td>172.21.21.61:2166367</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.31417</td><td style=\"text-align: right;\">3.8436 </td></tr>\n",
       "<tr><td>train_omics_87f7a_00059</td><td>TERMINATED</td><td>172.21.21.61:2166368</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.31058</td><td style=\"text-align: right;\">4.16245</td></tr>\n",
       "<tr><td>train_omics_87f7a_00060</td><td>TERMINATED</td><td>172.21.21.61:2166665</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.28981</td><td style=\"text-align: right;\">3.80703</td></tr>\n",
       "<tr><td>train_omics_87f7a_00061</td><td>TERMINATED</td><td>172.21.21.61:2166666</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.12924</td><td style=\"text-align: right;\">3.87403</td></tr>\n",
       "<tr><td>train_omics_87f7a_00062</td><td>TERMINATED</td><td>172.21.21.61:2166667</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.3238 </td><td style=\"text-align: right;\">4.03391</td></tr>\n",
       "<tr><td>train_omics_87f7a_00063</td><td>TERMINATED</td><td>172.21.21.61:2166668</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">       0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.34291</td><td style=\"text-align: right;\">3.93812</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:57:57,858\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/elliotw/ray_results/train_omics_2024-11-18_12-57-09' in 0.0080s.\n",
      "2024-11-18 12:57:57,865\tINFO tune.py:1041 -- Total run time: 48.42 seconds (48.40 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "grid_space = {\n",
    "    \"lr\": tune.grid_search([0.001, 0.005, 0.01, 0.05]),\n",
    "    \"B1\": 0.9,\n",
    "    \"B2\": 0.99,\n",
    "    \"dim1\": tune.grid_search([50,100]),\n",
    "    \"dim2\": tune.grid_search([50,100]),\n",
    "    \"dropout\": tune.grid_search([0.2, 0.5]),\n",
    "    \"batch\": 64,\n",
    "    \"momentum\": tune.grid_search([0,0.2]),\n",
    "    \"optimizer\": 1\n",
    "}\n",
    "# grid_search\n",
    "\n",
    "train_omics = tune.with_resources(train_omics, {\"gpu\": 0.25})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_omics,\n",
    "    param_space=grid_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # num_samples=100,\n",
    "        metric=\"score\",\n",
    "        mode=\"min\"\n",
    "    )\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08de615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'score': 3.713183784484863},\n",
      "  path='/home/elliotw/ray_results/train_omics_2024-11-18_12-57-09/train_omics_87f7a_00008_8_dim1=50,dim2=50,dropout=0.2000,lr=0.0050,momentum=0_2024-11-18_12-57-09',\n",
      "  filesystem='local',\n",
      "  checkpoint=None\n",
      ")\n",
      "{'lr': 0.005, 'B1': 0.9, 'B2': 0.99, 'dim1': 50.0, 'dim2': 50.0, 'dropout': 0.2, 'batch': 64, 'momentum': 0.0, 'optimizer': 1}\n"
     ]
    }
   ],
   "source": [
    "best_result = min(results, key= lambda x: x.metrics['score'])\n",
    "print(best_result)\n",
    "parameters = best_result.path.split('_')[-3].split(',')\n",
    "\n",
    "for param in parameters:\n",
    "    key, value = param.split('=')\n",
    "    value = float(value)\n",
    "    grid_space[key] = value\n",
    "\n",
    "print(grid_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bad4b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_loss  val_loss\n",
      "0     4.759322       NaN\n",
      "1     3.571152       NaN\n",
      "2     3.451598       NaN\n",
      "3     3.349008       NaN\n",
      "4     3.236879       NaN\n",
      "5     3.190073       NaN\n",
      "6     3.257966       NaN\n",
      "7     3.070701       NaN\n",
      "8     3.095080       NaN\n",
      "9     3.092274       NaN\n",
      "10    3.090242       NaN\n",
      "11    3.034384       NaN\n",
      "12    3.027818       NaN\n",
      "13    3.008570       NaN\n",
      "14    2.971441       NaN\n",
      "15    3.033185       NaN\n",
      "16    2.940410       NaN\n",
      "17    2.823087       NaN\n",
      "18    2.914625       NaN\n",
      "19    2.859583       NaN\n",
      "20    2.851130       NaN\n",
      "21    2.788332       NaN\n",
      "22    2.893174       NaN\n",
      "23    2.840199       NaN\n",
      "24    2.740641       NaN\n",
      "25    2.748704       NaN\n",
      "26    2.801127       NaN\n",
      "27    2.740373       NaN\n",
      "28    2.738158       NaN\n",
      "29    2.723378       NaN\n",
      "30    2.697249       NaN\n",
      "31    2.678042       NaN\n",
      "32    2.617781       NaN\n",
      "33    2.581289       NaN\n",
      "34    2.603884       NaN\n",
      "35    2.597042       NaN\n",
      "36    2.682450       NaN\n",
      "37    2.569641       NaN\n",
      "38    2.543880       NaN\n",
      "39    2.784017       NaN\n",
      "40    2.658553       NaN\n",
      "41    2.607677       NaN\n",
      "42    2.520529       NaN\n",
      "43    2.589159       NaN\n",
      "44    2.567275       NaN\n",
      "45    2.637771       NaN\n",
      "46    2.581590       NaN\n",
      "(0.6843838193791157, 1455, 671, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliotw/miniconda3/envs/MLenv/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "X_train= torch.tensor(train_set, dtype=torch.float32)\n",
    "\n",
    "# Ensure correct types for durations and events\n",
    "y_train_durations, y_train_events = y_train  # Unpack y_train into durations and events\n",
    "\n",
    "# Convert durations to float32 and events to int64\n",
    "y_train_fold = (\n",
    "    torch.tensor(y_train_durations, dtype=torch.float32),  # Durations as float32\n",
    "    torch.tensor(y_train_events, dtype=torch.float32)      # Events as int64\n",
    ")\n",
    "\n",
    "callbacks = [tt.cb.EarlyStopping(patience=5, dataset='train')]\n",
    "\n",
    "torch.manual_seed(3)\n",
    "# Define the model and move to GPU\n",
    "optimizer = tt.optim.RMSprop(lr=grid_space[\"lr\"], momentum=grid_space[\"momentum\"])\n",
    "# print(X_train)\n",
    "net = make_net(X_train.shape[1], 1, [int(grid_space['dim1']), int(grid_space['dim2'])], dropout=grid_space['dropout'])\n",
    "\n",
    "model = CoxPH(net, optimizer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "log = model.fit(X_train, y_train_fold, int(grid_space['batch']), 100, callbacks, verbose=False)\n",
    "print(log.to_pandas())\n",
    "\n",
    "risk = model.predict(test_set).squeeze()\n",
    "\n",
    "print(concordance_index_censored(y_test[1]==1, y_test[0], risk))\n",
    "# ev = EvalSurv(surv, y_test[0], y_test[1], censor_surv='km')\n",
    "\n",
    "# print(ev.concordance_td())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8dc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
